{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException, ElementNotVisibleException\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.request import urlopen\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib.request\n",
    "from urllib.request import HTTPError\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import codecs\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gCrawller:\n",
    "    count = 0 # 현재까지 크롤링된 URL 개수\n",
    "    \n",
    "    #크롤러 객체 초기화\n",
    "    def __init__(self, chromedriver_path, keyword, url_csv_filepath, PAUSE_TIME = 2):\n",
    "        self.keyword = keyword\n",
    "        self.target_url = 'https://www.google.co.kr/search?q='+keyword+'&source=lnms&tbm=isch&sa=X&ved=0ahUKEwic-taB9IXVAhWDHpQKHXOjC14Q_AUIBigB&biw=1842&bih=990'\n",
    "        self.PAUSE_TIME = PAUSE_TIME\n",
    "        self.driver = webdriver.Chrome(chromedriver_path)\n",
    "        self.url_csv_filepath = url_csv_filepath\n",
    "        gCrawller.count = 0\n",
    "       \n",
    "    #크롤러 객체 준비\n",
    "    def crawlling_ready(self):\n",
    "        self.driver.implicitly_wait(3) \n",
    "        self.driver.get(self.target_url)\n",
    "        \n",
    "        time.sleep(self.PAUSE_TIME)\n",
    "        self.first_img = self.driver.find_element_by_xpath('//*[@id=\"rg_s\"]/div[1]')\n",
    "        self.first_img.click()\n",
    "        \n",
    "        time.sleep(self.PAUSE_TIME)\n",
    "        self.next_btn = self.driver.find_element_by_xpath('//a[@id=\"irc-rab\"]')\n",
    "        self.more_btn = self.driver.find_element_by_xpath('//*[@id=\"irc_cc\"]/div[2]/div[3]/div[3]/div/div[2]/div[8]/a/span')\n",
    "        self.more_btn.click()\n",
    "        \n",
    "    def back_and_start_over(self):\n",
    "        url = self.driver.current_url\n",
    "        item = []\n",
    "        item.append(url)\n",
    "        self.write_csv_url(item)\n",
    "        gCrawller.count+=1\n",
    "        self.driver.back()\n",
    "        time.sleep(self.PAUSE_TIME)\n",
    "        \n",
    "        try:\n",
    "            self.next_btn.click()\n",
    "        \n",
    "        except StaleElementReferenceException:\n",
    "            time.sleep(self.PAUSE_TIME)\n",
    "            self.next_btn = self.driver.find_element_by_xpath('//a[@id=\"irc-rab\"]')\n",
    "            self.next_btn.click()\n",
    "            \n",
    "        time.sleep(self.PAUSE_TIME)\n",
    "        self.driver.refresh()\n",
    "        time.sleep(self.PAUSE_TIME)\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                self.more_btn = self.driver.find_element_by_xpath('//*[@id=\"irc_cc\"]/div[2]/div[3]/div[3]/div/div[2]/div[8]/a/span')\n",
    "                self.more_btn.click()\n",
    "                break\n",
    "            \n",
    "            except NoSuchElementException:\n",
    "                self.next_btn = self.driver.find_element_by_xpath('//a[@id=\"irc-rab\"]')\n",
    "                time.sleep(self.PAUSE_TIME)\n",
    "                self.next_btn.click()\n",
    "                self.driver.refresh()\n",
    "                #break\n",
    "                \n",
    "            except ElementNotVisibleException:\n",
    "                time.sleep(self.PAUSE_TIME)\n",
    "                self.more_btn = self.driver.find_element_by_xpath('//*[@id=\"irc_cc\"]/div[2]/div[3]/div[3]/div/div[2]/div[8]/a/span')    \n",
    "    \n",
    "    def write_csv_url(self,list):\n",
    "        with codecs.open(self.url_csv_filepath,\"a\",\"utf-8\") as fp:\n",
    "            writer=csv.writer(fp,delimiter=\",\")\n",
    "            writer.writerow(list)\n",
    "    \n",
    "    def main(self):\n",
    "        self.crawlling_ready()\n",
    "        while True:\n",
    "            if gCrawller.count>20:\n",
    "                break\n",
    "            self.back_and_start_over()\n",
    "            time.sleep(self.PAUSE_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword = input(\"검색할 이미지를 입력하세요 : \")\n",
    "keyword_list = ['피자', '파전']\n",
    "\n",
    "for keyword in keyword_list:\n",
    "    chromedriver_path='C:/Users/acorn/Desktop/weather/chromedriver_win32/chromedriver'\n",
    "    url_csv_filepath = 'C:/Users/acorn/weather_bigdata/original_url/url_'+keyword+'.csv'\n",
    "    gc = gCrawller(chromedriver_path, keyword, url_csv_filepath)\n",
    "    gc.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
